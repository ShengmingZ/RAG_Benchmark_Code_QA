retrieval_instruct_prompt_1 = """Instruction: Given the Problem, some Potential Reference Documents, and the Code Snippet to be completed, 
complete the unfinished part of Code Snippet according to the Problem and Documents
"""

retrieval_instruct_prompt_2 = """Instruction: Given some Potential Reference Documents and the Code Snippet to be completed, 
complete the unfinished part of the Code Snippet
"""

retrieval_3shots_prompt_1 = ['### Problem:\nI have an array of random floats and I need to compare it to another one that has the same values in a different order. For that matter I use the sum, product (and other combinations depending on the dimension of the table hence the number of equations needed).\nNevertheless, I encountered a precision issue when I perform the sum (or product) on the array depending on the order of the values.\nHere is a simple standalone example to illustrate this issue :\nimport numpy as np\nn = 10\nm = 4\ntag = np.random.rand(n, m)\ns1 = np.sum(tag, axis=1)\ns2 = np.sum(tag[:, ::-1], axis=1)\n# print the number of times s1 is not equal to s2 (should be 0)\nprint np.nonzero(s1 != s2)[0].shape[0]\nIf you execute this code it sometimes tells you that s1 and s2 are not equal and the differents is of magnitude of the computer precision. However, such elements should be considered as equal under this circumstance.\nThe problem is I need to use those in functions like np.in1d where I can\'t really give a tolerance...\nWhat I want as the result is the number of truly different elements in s1 and s2, as shown in code snippet above.\nIs there a way to avoid this issue?\n\n\n### Potential Document:\npotential document 0: numpy.reference.generated.numpy.ma.maskedarray.sum: numpy.ma.MaskedArray.sum method   ma.MaskedArray.sum(axis=None, dtype=None, out=None, keepdims=<no value>)[source]   Return the sum of the array elements over the given axis. Masked elements are set to 0 internally. Refer to numpy.sum for full documentation.  See also  numpy.ndarray.sum  corresponding function for ndarrays  numpy.sum  equivalent function    Examples >>> x = np.ma.array([[1,2,3],[4,5,6],[7,8,9]], mask=[0] + [1,0]*4) >>> x masked_array(   data=[[1, --, 3],         [--, 5, --],         [7, --, 9]],   mask=[[False,  True, False],         [ True, False,  True],         [False,  True, False]],   fill_value=999999) >>> x.sum() 25 >>> x.sum(axis=1) masked_array(data=[4, 5, 16],              mask=[False, False, False],        fill_value=999999) >>> x.sum(axis=0) masked_array(data=[8, 5, 12],              mask=[False, False, False],        fill_value=999999) >>> print(type(x.sum(axis=0, dtype=np.int64)[0])) <class \'numpy.int64\'>\npotential document 1: numpy.reference.generated.numpy.isclose: numpy.isclose   numpy.isclose(a, b, rtol=1e-05, atol=1e-08, equal_nan=False)[source]   Returns a boolean array where two arrays are element-wise equal within a tolerance. The tolerance values are positive, typically very small numbers. The relative difference (rtol * abs(b)) and the absolute difference atol are added together to compare against the absolute difference between a and b.  Warning The default atol is not appropriate for comparing numbers that are much smaller than one (see Notes).   Parameters    a, barray_like   Input arrays to compare.   rtolfloat   The relative tolerance parameter (see Notes).   atolfloat   The absolute tolerance parameter (see Notes).   equal_nanbool   Whether to compare NaN’s as equal. If True, NaN’s in a will be considered equal to NaN’s in b in the output array.    Returns    yarray_like   Returns a boolean array of where a and b are equal within the given tolerance. If both a and b are scalars, returns a single boolean value.      See also  allclose math.isclose   Notes  New in version 1.7.0.  For finite values, isclose uses the following equation to test whether two floating point values are equivalent. absolute(a - b) <= (atol + rtol * absolute(b)) Unlike the built-in math.isclose, the above equation is not symmetric in a and b – it assumes b is the reference value – so that isclose(a, b) might be different from isclose(b, a). Furthermore, the default value of atol is not zero, and is used to determine what small values should be considered close to zero. The default value is appropriate for expected values of order unity: if the expected values are significantly smaller than one, it can result in false positives. atol should be carefully selected for the use case at hand. A zero value for atol will result in False if either a or b is zero. isclose is not defined for non-numeric data types. bool is considered a numeric data-type for this purpose. Examples >>> np.isclose([1e10,1e-7], [1.00001e10,1e-8]) array([ True, False]) >>> np.isclose([1e10,1e-8], [1.00001e10,1e-9]) array([ True, True]) >>> np.isclose([1e10,1e-8], [1.0001e10,1e-9]) array([False,  True]) >>> np.isclose([1.0, np.nan], [1.0, np.nan]) array([ True, False]) >>> np.isclose([1.0, np.nan], [1.0, np.nan], equal_nan=True) array([ True, True]) >>> np.isclose([1e-8, 1e-7], [0.0, 0.0]) array([ True, False]) >>> np.isclose([1e-100, 1e-7], [0.0, 0.0], atol=0.0) array([False, False]) >>> np.isclose([1e-10, 1e-10], [1e-20, 0.0]) array([ True,  True]) >>> np.isclose([1e-10, 1e-10], [1e-20, 0.999999e-10], atol=0.0) array([False,  True])\n\n\n### Uncompleted Code Snippet:\n<code>\nimport numpy as np\nn = 20\nm = 10\ntag = np.random.rand(n, m)\ns1 = np.sum(tag, axis=1)\ns2 = np.sum(tag[:, ::-1], axis=1)\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\n\n\n### Answer:\nresult = (~np.isclose(s1,s2)).sum()\n\n\n\n### END\n\n\n### Problem:\nI\'m using tensorflow 2.10.0.\n\nimport tensorflow as tf\nx = [[1,2,3],[4,5,6]]\ny = [0,1]\nz = [1,2]\nx = tf.constant(x)\ny = tf.constant(y)\nz = tf.constant(z)\nm = x[y,z]\n\nWhat I expect is m = [2,6]\nI can get the result by theano or numpy. How I get the result using tensorflow?\n\n\n\n\n### Potential Document:\npotential document 0: tensorflow.gather_nd: tf.gather_nd       View source on GitHub    Gather slices from params into a Tensor with shape specified by indices.  tf.gather_nd(     params, indices, batch_dims=0, name=None )  indices is an K-dimensional integer tensor, best thought of as a (K-1)-dimensional tensor of indices into params, where each element defines a slice of params: output[\\\\(i_0, ..., i_{K-2}\\\\)] = params[indices[\\\\(i_0, ..., i_{K-2}\\\\)]]  Whereas in tf.gather indices defines slices into the first dimension of params, in tf.gather_nd, indices defines slices into the first N dimensions of params, where N = indices.shape[-1]. The last dimension of indices can be at most the rank of params: indices.shape[-1] <= params.rank  The last dimension of indices corresponds to elements (if indices.shape[-1] == params.rank) or slices (if indices.shape[-1] < params.rank) along dimension indices.shape[-1] of params. The output tensor has shape indices.shape[:-1] + params.shape[indices.shape[-1]:]  Additionally both \'params\' and \'indices\' can have M leading batch dimensions that exactly match. In this case \'batch_dims\' must be M. Note that on CPU, if an out of bound index is found, an error is returned. On GPU, if an out of bound index is found, a 0 is stored in the corresponding output value. Some examples below. Simple indexing into a matrix: indices = [[0, 0], [1, 1]] params = [[\'a\', \'b\'], [\'c\', \'d\']] output = [\'a\', \'d\']  Slice indexing into a matrix: indices = [[1], [0]] params = [[\'a\', \'b\'], [\'c\', \'d\']] output = [[\'c\', \'d\'], [\'a\', \'b\']]  Indexing into a 3-tensor: indices = [[1]] params = [[[\'a0\', \'b0\'], [\'c0\', \'d0\']],           [[\'a1\', \'b1\'], [\'c1\', \'d1\']]] output = [[[\'a1\', \'b1\'], [\'c1\', \'d1\']]]   indices = [[0, 1], [1, 0]] params = [[[\'a0\', \'b0\'], [\'c0\', \'d0\']],           [[\'a1\', \'b1\'], [\'c1\', \'d1\']]] output = [[\'c0\', \'d0\'], [\'a1\', \'b1\']]   indices = [[0, 0, 1], [1, 0, 1]] params = [[[\'a0\', \'b0\'], [\'c0\', \'d0\']],           [[\'a1\', \'b1\'], [\'c1\', \'d1\']]] output = [\'b0\', \'b1\']  The examples below are for the case when only indices have leading extra dimensions. If both \'params\' and \'indices\' have leading batch dimensions, use the \'batch_dims\' parameter to run gather_nd in batch mode. Batched indexing into a matrix: indices = [[[0, 0]], [[0, 1]]] params = [[\'a\', \'b\'], [\'c\', \'d\']] output = [[\'a\'], [\'b\']]  Batched slice indexing into a matrix: indices = [[[1]], [[0]]] params = [[\'a\', \'b\'], [\'c\', \'d\']] output = [[[\'c\', \'d\']], [[\'a\', \'b\']]]  Batched indexing into a 3-tensor: indices = [[[1]], [[0]]] params = [[[\'a0\', \'b0\'], [\'c0\', \'d0\']],           [[\'a1\', \'b1\'], [\'c1\', \'d1\']]] output = [[[[\'a1\', \'b1\'], [\'c1\', \'d1\']]],           [[[\'a0\', \'b0\'], [\'c0\', \'d0\']]]]  indices = [[[0, 1], [1, 0]], [[0, 0], [1, 1]]] params = [[[\'a0\', \'b0\'], [\'c0\', \'d0\']],           [[\'a1\', \'b1\'], [\'c1\', \'d1\']]] output = [[[\'c0\', \'d0\'], [\'a1\', \'b1\']],           [[\'a0\', \'b0\'], [\'c1\', \'d1\']]]   indices = [[[0, 0, 1], [1, 0, 1]], [[0, 1, 1], [1, 1, 0]]] params =\npotential document 1: numpy.reference.generated.numpy.ma.maskedarray.__copy__: numpy.ma.MaskedArray.__copy__ method   ma.MaskedArray.__copy__()   Used if copy.copy is called on an array. Returns a copy of the array. Equivalent to a.copy(order=\'K\').\n\n\n### Uncompleted Code Snippet:\n<code>\nimport tensorflow as tf\n\n\nx = [[1,2,3],[4,5,6]]\ny = [0,1]\nz = [1,2]\nx = tf.constant(x)\ny = tf.constant(y)\nz = tf.constant(z)\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\n\n\n### Answer:\ndef g(x,y,z):\n    return tf.gather_nd(x, [y, z])\n\nresult = g(x.__copy__(),y.__copy__(),z.__copy__())\n\n\n\n### END\n\n\n### Problem:\nSample dataframe:\ndf = pd.DataFrame({"A": [1, 2, 3], "B": [4, 5, 6]})\n\nI\'d like to add sigmoids of each existing column to the dataframe and name them based on existing column names with a prefix, e.g. sigmoid_A is an sigmoid of column A and so on.\nThe resulting dataframe should look like so:\nresult = pd.DataFrame({"A": [1, 2, 3], "B": [4, 5, 6], "sigmoid_A": [1/(1+e^(-1)), 1/(1+e^(-2)), 1/(1+e^(-3))], "sigmoid_B": [1/(1+e^(-4)), 1/(1+e^(-5)), 1/(1+e^(-6))]})\n\nNotice that e is the natural constant.\nObviously there are redundant methods like doing this in a loop, but there should exist much more pythonic ways of doing it and after searching for some time I didn\'t find anything. I understand that this is most probably a duplicate; if so, please point me to an existing answer.\n\n\n\n### Potential Document:\npotential document 0: pandas.reference.api.pandas.core.groupby.groupby.apply: pandas.core.groupby.GroupBy.apply   GroupBy.apply(func, *args, **kwargs)[source]   Apply function func group-wise and combine the results together. The function passed to apply must take a dataframe as its first argument and return a DataFrame, Series or scalar. apply will then take care of combining the results back together into a single dataframe or series. apply is therefore a highly flexible grouping method. While apply is a very flexible method, its downside is that using it can be quite a bit slower than using more specific methods like agg or transform. Pandas offers a wide range of method that will be much faster than using apply for their specific purposes, so try to use them before reaching for apply.  Parameters    func:callable   A callable that takes a dataframe as its first argument, and returns a dataframe, a series or a scalar. In addition the callable may take positional and keyword arguments.   args, kwargs:tuple and dict   Optional positional and keyword arguments to pass to func.    Returns    applied:Series or DataFrame      See also  pipe  Apply function to the full GroupBy object instead of to each group.  aggregate  Apply aggregate function to the GroupBy object.  transform  Apply function column-by-column to the GroupBy object.  Series.apply  Apply a function to a Series.  DataFrame.apply  Apply a function to each row or column of a DataFrame.    Notes  Changed in version 1.3.0: The resulting dtype will reflect the return value of the passed func, see the examples below.  Functions that mutate the passed object can produce unexpected behavior or errors and are not supported. See Mutating with User Defined Function (UDF) methods for more details. Examples  >>> df = pd.DataFrame({\'A\': \'a a b\'.split(), ...                    \'B\': [1,2,3], ...                    \'C\': [4,6,5]}) >>> g = df.groupby(\'A\')   Notice that g has two groups, a and b. Calling apply in various ways, we can get different grouping results: Example 1: below the function passed to apply takes a DataFrame as its argument and returns a DataFrame. apply combines the result for each group together into a new DataFrame:  >>> g[[\'B\', \'C\']].apply(lambda x: x / x.sum())           B    C 0  0.333333  0.4 1  0.666667  0.6 2  1.000000  1.0   Example 2: The function passed to apply takes a DataFrame as its argument and returns a Series. apply combines the result for each group together into a new DataFrame.  Changed in version 1.3.0: The resulting dtype will reflect the return value of the passed func.   >>> g[[\'B\', \'C\']].apply(lambda x: x.astype(float).max() - x.min())      B    C A a  1.0  2.0 b  0.0  0.0   Example 3: The function passed to apply takes a DataFrame as its argument and returns a scalar. apply combines the result for each group together into a Series, including setting the index as appropriate:  >>> g.apply(lambda x: x.C.max() - x.B.min()) A a    5 b    2 dtype: int64\npotential document 1: pandas.reference.api.pandas.dataframe.add_prefix: pandas.DataFrame.add_prefix   DataFrame.add_prefix(prefix)[source]   Prefix labels with string prefix. For Series, the row labels are prefixed. For DataFrame, the column labels are prefixed.  Parameters    prefix:str   The string to add before each label.    Returns   Series or DataFrame  New Series or DataFrame with updated labels.      See also  Series.add_suffix  Suffix row labels with string suffix.  DataFrame.add_suffix  Suffix column labels with string suffix.    Examples  >>> s = pd.Series([1, 2, 3, 4]) >>> s 0    1 1    2 2    3 3    4 dtype: int64    >>> s.add_prefix(\'item_\') item_0    1 item_1    2 item_2    3 item_3    4 dtype: int64    >>> df = pd.DataFrame({\'A\': [1, 2, 3, 4], \'B\': [3, 4, 5, 6]}) >>> df    A  B 0  1  3 1  2  4 2  3  5 3  4  6    >>> df.add_prefix(\'col_\')      col_A  col_B 0       1       3 1       2       4 2       3       5 3       4       6\npotential document 2: pandas.reference.api.pandas.dataframe.join: pandas.DataFrame.join   DataFrame.join(other, on=None, how=\'left\', lsuffix=\'\', rsuffix=\'\', sort=False)[source]   Join columns of another DataFrame. Join columns with other DataFrame either on index or on a key column. Efficiently join multiple DataFrame objects by index at once by passing a list.  Parameters    other:DataFrame, Series, or list of DataFrame   Index should be similar to one of the columns in this one. If a Series is passed, its name attribute must be set, and that will be used as the column name in the resulting joined DataFrame.   on:str, list of str, or array-like, optional   Column or index level name(s) in the caller to join on the index in other, otherwise joins index-on-index. If multiple values given, the other DataFrame must have a MultiIndex. Can pass an array as the join key if it is not already contained in the calling DataFrame. Like an Excel VLOOKUP operation.   how:{‘left’, ‘right’, ‘outer’, ‘inner’}, default ‘left’   How to handle the operation of the two objects.  left: use calling frame’s index (or column if on is specified) right: use other’s index. outer: form union of calling frame’s index (or column if on is specified) with other’s index, and sort it. lexicographically. inner: form intersection of calling frame’s index (or column if on is specified) with other’s index, preserving the order of the calling’s one.  cross: creates the cartesian product from both frames, preserves the order of the left keys.  New in version 1.2.0.      lsuffix:str, default ‘’   Suffix to use from left frame’s overlapping columns.   rsuffix:str, default ‘’   Suffix to use from right frame’s overlapping columns.   sort:bool, default False   Order result DataFrame lexicographically by the join key. If False, the order of the join key depends on the join type (how keyword).    Returns   DataFrame  A dataframe containing columns from both the caller and other.      See also  DataFrame.merge  For column(s)-on-column(s) operations.    Notes Parameters on, lsuffix, and rsuffix are not supported when passing a list of DataFrame objects. Support for specifying index levels as the on parameter was added in version 0.23.0. Examples  >>> df = pd.DataFrame({\'key\': [\'K0\', \'K1\', \'K2\', \'K3\', \'K4\', \'K5\'], ...                    \'A\': [\'A0\', \'A1\', \'A2\', \'A3\', \'A4\', \'A5\']})    >>> df   key   A 0  K0  A0 1  K1  A1 2  K2  A2 3  K3  A3 4  K4  A4 5  K5  A5    >>> other = pd.DataFrame({\'key\': [\'K0\', \'K1\', \'K2\'], ...                       \'B\': [\'B0\', \'B1\', \'B2\']})    >>> other   key   B 0  K0  B0 1  K1  B1 2  K2  B2   Join DataFrames using their indexes.  >>> df.join(other, lsuffix=\'_caller\', rsuffix=\'_other\')   key_caller   A key_other    B 0         K0  A0        K0   B0 1         K1  A1        K1   B1 2         K2  A2        K2   B2 3         K3  A3       NaN  NaN 4         K4  A4       NaN  NaN 5         K5  A5       NaN  NaN   If we want to join using the key columns, we need to set key to be the index in both df and other. The joined DataFrame will have key as its index.  >>> df.set_index(\'key\').join(other.set_index(\'key\'))       A    B key K0   A0   B0 K1   A1   B1 K2   A2   B2 K3   A3  NaN K4   A4  NaN K5   A5  NaN   Another option to join using the key columns is to use the on parameter. DataFrame.join always uses other’s index but we can use any column in df. This method preserves the original DataFrame’s index in the result.  >>> df.join(other.set_index(\'key\'), on=\'key\')   key   A    B 0  K0  A0   B0 1  K1  A1   B1 2  K2\n\n\n### Uncompleted Code Snippet:\n<code>\nimport pandas as pd\n\n\ndf = pd.DataFrame({"A": [1, 2, 3], "B": [4, 5, 6]})\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\n\n\n### Answer:\nimport math\ndef g(df):\n    return df.join(df.apply(lambda x: 1/(1+math.e**(-x))).add_prefix(\'sigmoid_\'))\n\nresult = g(df.copy())\n\n\n\n### END\n\n\n']
retrieval_3shots_prompt_1 = retrieval_3shots_prompt_1[0]


retrieval_3shots_prompt_2 = ['### Potential Document:\npotential document 0: matplotlib._as_gen.matplotlib.pyplot.yticks: matplotlib.pyplot.yticks   matplotlib.pyplot.yticks(ticks=None, labels=None, **kwargs)[source]   Get or set the current tick locations and labels of the y-axis. Pass no arguments to return the current values without modifying them.  Parameters    ticksarray-like, optional   The list of ytick locations. Passing an empty list removes all yticks.   labelsarray-like, optional   The labels to place at the given ticks locations. This argument can only be passed if ticks is passed as well.  **kwargs  Text properties can be used to control the appearance of the labels.    Returns   locs  The list of ytick locations.  labels  The list of ylabel Text objects.     Notes Calling this function with no arguments (e.g. yticks()) is the pyplot equivalent of calling get_yticks and get_yticklabels on the current axes. Calling this function with arguments is the pyplot equivalent of calling set_yticks and set_yticklabels on the current axes. Examples >>> locs, labels = yticks()  # Get the current locations and labels. >>> yticks(np.arange(0, 1, step=0.2))  # Set label locations. >>> yticks(np.arange(3), [\'Tom\', \'Dick\', \'Sue\'])  # Set text labels. >>> yticks([0, 1, 2], [\'January\', \'February\', \'March\'], ...        rotation=45)  # Set text labels and properties. >>> yticks([])  # Disable yticks.     Examples using matplotlib.pyplot.yticks      Table Demo\n\n\n### Uncompleted Code Snippet:\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.arange(2010, 2020)\ny = np.arange(10)\nplt.plot(x, y)\n\n# Set the transparency of xtick labels to be 0.5\n# SOLUTION START\n\n\n### Answer:\nplt.yticks(alpha=0.5)\n\n\n### END\n\n\n### Potential Document:\npotential document 0: matplotlib._as_gen.matplotlib.axes.axes.plot: matplotlib.axes.Axes.plot   Axes.plot(*args, scalex=True, scaley=True, data=None, **kwargs)[source]   Plot y versus x as lines and/or markers. Call signatures: plot([x], y, [fmt], *, data=None, **kwargs) plot([x], y, [fmt], [x2], y2, [fmt2], ..., **kwargs)  The coordinates of the points or line nodes are given by x, y. The optional parameter fmt is a convenient way for defining basic formatting like color, marker and linestyle. It\'s a shortcut string notation described in the Notes section below. >>> plot(x, y)        # plot x and y using default line style and color >>> plot(x, y, \'bo\')  # plot x and y using blue circle markers >>> plot(y)           # plot y using x as index array 0..N-1 >>> plot(y, \'r+\')     # ditto, but with red plusses  You can use Line2D properties as keyword arguments for more control on the appearance. Line properties and fmt can be mixed. The following two calls yield identical results: >>> plot(x, y, \'go--\', linewidth=2, markersize=12) >>> plot(x, y, color=\'green\', marker=\'o\', linestyle=\'dashed\', ...      linewidth=2, markersize=12)  When conflicting with fmt, keyword arguments take precedence. Plotting labelled data There\'s a convenient way for plotting objects with labelled data (i.e. data that can be accessed by index obj[\'y\']). Instead of giving the data in x and y, you can provide the object in the data parameter and just give the labels for x and y: >>> plot(\'xlabel\', \'ylabel\', data=obj)  All indexable objects are supported. This could e.g. be a dict, a pandas.DataFrame or a structured numpy array. Plotting multiple sets of data There are various ways to plot multiple sets of data.   The most straight forward way is just to call plot multiple times. Example: >>> plot(x1, y1, \'bo\') >>> plot(x2, y2, \'go\')    If x and/or y are 2D arrays a separate data set will be drawn for every column. If both x and y are 2D, they must have the same shape. If only one of them is 2D with shape (N, m) the other must have length N and will be used for every data set m. Example: >>> x = [1, 2, 3] >>> y = np.array([[1, 2], [3, 4], [5, 6]]) >>> plot(x, y)  is equivalent to: >>> for col in range(y.shape[1]): ...     plot(x, y[:, col])    The third way is to specify multiple sets of [x], y, [fmt] groups: >>> plot(x1, y1, \'g^\', x2, y2, \'g-\')  In this case, any additional keyword argument applies to all datasets. Also this syntax cannot be combined with the data parameter.   By default, each line is assigned a different style specified by a \'style cycle\'. The fmt and line property parameters are only necessary if you want explicit deviations from these defaults. Alternatively, you can also change the style cycle using rcParams["axes.prop_cycle"] (default: cycler(\'color\', [\'#1f77b4\', \'#ff7f0e\', \'#2ca02c\', \'#d62728\', \'#9467bd\', \'#8c564b\', \'#e377c2\', \'#7f7f7f\', \'#bcbd22\', \'#17becf\'])).  Parameters    x, yarray-like or scalar   The horizontal / vertical coordinates of the data points. x values are optional and default to range(len(y)). Commonly, these parameters are 1D arrays. They can also be scalars, or two-dimensional (in that case, the columns represent separate data sets). These arguments cannot be passed as keywords.   fmtstr, optional   A format string, e.g. \'ro\' for red circles. See the Notes section for a full description of the format strings. Format strings are just an abbreviation for quickly setting basic line properties. All of these and more can also be controlled by keyword arguments. This argument cannot be passed as keyword.   dataindexable object, optional   An object with labelled data. If given, provide the label names to plot in x and y.  Note Technically there\'s a slight ambiguity in calls where the second label is a valid fmt. plot(\'n\', \'o\', data=obj) could be plt(x, y) or plt(y, fmt).\npotential document 1: matplotlib._as_gen.matplotlib.axes.axes.tick_params: matplotlib.axes.Axes.tick_params   Axes.tick_params(axis=\'both\', **kwargs)[source]   Change the appearance of ticks, tick labels, and gridlines. Tick properties that are not explicitly set using the keyword arguments remain unchanged unless reset is True.  Parameters    axis{\'x\', \'y\', \'both\'}, default: \'both\'   The axis to which the parameters are applied.   which{\'major\', \'minor\', \'both\'}, default: \'major\'   The group of ticks to which the parameters are applied.   resetbool, default: False   Whether to reset the ticks to defaults before updating them.    Other Parameters    direction{\'in\', \'out\', \'inout\'}   Puts ticks inside the axes, outside the axes, or both.   lengthfloat   Tick length in points.   widthfloat   Tick width in points.   colorcolor   Tick color.   padfloat   Distance in points between tick and label.   labelsizefloat or str   Tick label font size in points or as a string (e.g., \'large\').   labelcolorcolor   Tick label color.   colorscolor   Tick color and label color.   zorderfloat   Tick and label zorder.   bottom, top, left, rightbool   Whether to draw the respective ticks.   labelbottom, labeltop, labelleft, labelrightbool   Whether to draw the respective tick labels.   labelrotationfloat   Tick label rotation   grid_colorcolor   Gridline color.   grid_alphafloat   Transparency of gridlines: 0 (transparent) to 1 (opaque).   grid_linewidthfloat   Width of gridlines in points.   grid_linestylestr   Any valid Line2D line style spec.     Examples ax.tick_params(direction=\'out\', length=6, width=2, colors=\'r\',                grid_color=\'r\', grid_alpha=0.5)  This will make all major ticks be red, pointing out of the box, and with dimensions 6 points by 2 points. Tick labels will also be red. Gridlines will be red and translucent.    Examples using matplotlib.axes.Axes.tick_params      Scatter plot with histograms        Creating annotated heatmaps        Axes Props        Broken Axis        Plots with different scales        Polar Legend        Color Demo        Inset Locator Demo        Inset Locator Demo2        Make Room For Ylabel Using Axesgrid        Simple Axes Divider 3        Anatomy of a figure        Bachelor\'s degrees by gender        Anscombe\'s quartet        Multiple Yaxis With Spines        Major and minor ticks        Text in Matplotlib Plots\n\n\n### Uncompleted Code Snippet:\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.arange(10)\ny = np.arange(10)\n\n# Plot y over x in a line chart. Show x axis tick labels but hide the x axis ticks\n# SOLUTION START\n\n\n### Answer:\nplt.plot(x, y)\nplt.tick_params(bottom=False, labelbottom=True)\n\n\n### END\n\n\n### Potential Document:\npotential document 0: matplotlib._as_gen.matplotlib.axes.axes.set_ylabel: matplotlib.axes.Axes.set_ylabel   Axes.set_ylabel(ylabel, fontdict=None, labelpad=None, *, loc=None, **kwargs)[source]   Set the label for the y-axis.  Parameters    ylabelstr   The label text.   labelpadfloat, default: rcParams["axes.labelpad"] (default: 4.0)   Spacing in points from the Axes bounding box including ticks and tick labels. If None, the previous value is left as is.   loc{\'bottom\', \'center\', \'top\'}, default: rcParams["yaxis.labellocation"] (default: \'center\')   The label position. This is a high-level alternative for passing parameters y and horizontalalignment.    Other Parameters    **kwargsText properties   Text properties control the appearance of the label.      See also  text  Documents the properties supported by Text.       Examples using matplotlib.axes.Axes.set_ylabel      Bar Label Demo        Stacked bar chart        Grouped bar chart with labels        CSD Demo        Fill Between and Alpha        Hatch-filled histograms        Hat graph        Psd Demo        Scatter Demo2        Stackplots and streamgraphs        Contourf Demo        Creating annotated heatmaps        Tricontour Demo        Tripcolor Demo        Triplot Demo        Aligning Labels        Axes Demo        Axis Label Position        Resizing axes with constrained layout        Resizing axes with tight layout        Figure labels: suptitle, supxlabel, supylabel        Invert Axes        Secondary Axis        Figure subfigures        Multiple subplots        Plots with different scales        Box plots with custom fill colors        Boxplots        Box plot vs. violin plot comparison        Violin plot customization        Using histograms to plot a cumulative distribution        Some features of the histogram (hist) function        Producing multiple histograms side by side        Using accented text in matplotlib        Date tick labels        Legend Demo        Mathtext        Multiline        Rendering math equations using TeX        Simple axes labels        Text Commands        Color Demo        Line, Poly and RegularPoly Collection with autoscaling        Ellipse Collection        Dark background style sheet        Make Room For Ylabel Using Axesgrid        Parasite Simple        Parasite Axes demo        Parasite axis demo        Ticklabel alignment        Simple Axis Direction03        Simple Axisline        Anatomy of a figure        XKCD        Pythonic Matplotlib        Plot 2D data on 3D plot        Create 2D bar graphs in different planes        3D errorbars        Lorenz Attractor        2D and 3D Axes in same Figure        Automatic Text Offsetting        3D scatterplot        3D surface with polar coordinates        Text annotations in 3D        Log Bar        Symlog Demo        MRI With EEG        Topographic hillshading        Multiple Yaxis With Spines        Basic Usage        Artist tutorial        Constrained Layout Guide        Tight Layout guide        Arranging multiple Axes in a Figure        Choosing Colormaps in Matplotlib        Text in Matplotlib Plots\npotential document 1: matplotlib.cbook_api#matplotlib.cbook.flatten: matplotlib.cbook.flatten(seq, scalarp=<function is_scalar_or_string>)[source]   Return a generator of flattened nested containers. For example: >>> from matplotlib.cbook import flatten >>> l = ((\'John\', [\'Hunter\']), (1, 23), [[([42, (5, 23)], )]]) >>> print(list(flatten(l))) [\'John\', \'Hunter\', 1, 23, 42, 5, 23]  By: Composite of Holger Krekel and Luther Blissett From: https://code.activestate.com/recipes/121294/ and Recipe 1.12 in cookbook\n\n\n### Uncompleted Code Snippet:\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndf = sns.load_dataset("exercise")\n\n# Make catplots of scatter plots by using "time" as x, "pulse" as y, "kind" as hue, and "diet" as col\n# Do not show any ylabel on either subplot\n# SOLUTION START\n\n\n### Answer:\ng = sns.catplot(x="time", y="pulse", hue="kind", col="diet", data=df)\naxs = g.axes.flatten()\naxs[0].set_ylabel("")\n\n\n### END\n\n\n']
retrieval_3shots_prompt_2 = retrieval_3shots_prompt_2[0]


if __name__ == '__main__':
    import sys, platform
    import random

    system = platform.system()
    if system == 'Darwin':
        root_path = '/Users/zhaoshengming/Code_RAG_Benchmark'
    elif system == 'Linux':
        root_path = '/home/zhaoshengming/Code_RAG_Benchmark'
    sys.path.insert(0, root_path)
    from dataset_utils.dataset_configs import DS1000Loader
    from generator.generate_utils import truncate_too_long_doc

    # def classify_prompt(data_list):
    #     type_1_list, type_2_list = [], []
    #     for data in data_list:
    #         if 'Problem:' in data['nl']:
    #             type_1_list.append(data)
    #         else:
    #             type_2_list.append(data)
    #     return type_1_list, type_2_list
    #
    # ds1000_loader = DS1000Loader()
    # sampled_data = ds1000_loader.load_qs_list(sampled=True)
    # sampled_data_type1, sampled_data_type2 = classify_prompt(sampled_data)
    # sampled_id_type1, sampled_id_type2 = [data['qs_id'] for data in sampled_data_type1], [data['qs_id'] for data in sampled_data_type2]
    # all_data = ds1000_loader.load_qs_list(sampled=False)
    # all_data_type1, all_data_type2 = classify_prompt(all_data)
    # all_id_type1, all_id_type2 = [data['qs_id'] for data in all_data_type1], [data['qs_id'] for data in all_data_type2]
    # rest_id_type1, rest_id_type2 = [id for id in all_id_type1 if id not in sampled_id_type1], [id for id in all_id_type2 if id not in sampled_id_type2]
    # sampled_rest_id_type1 = random.sample(rest_id_type1, 10)
    # sampled_rest_id_type2 = random.sample(rest_id_type2, 10)
    #
    # print(sampled_rest_id_type1)
    # print(sampled_rest_id_type2)

    sampled_rest_id_type1 = ['Numpy_200', 'Tensorflow_25', 'Pandas_53', 'Numpy_41', 'Scipy_98', 'Scipy_66', 'Tensorflow_8', 'Numpy_96', 'Scipy_56', 'Numpy_166']
    sampled_rest_id_type2 = ['Matplotlib_93', 'Matplotlib_142', 'Matplotlib_145', 'Matplotlib_33', 'Matplotlib_80', 'Matplotlib_20', 'Matplotlib_44', 'Matplotlib_120', 'Matplotlib_14', 'Matplotlib_99']

    def prepare_prompt(nl, ret_docs, answer):
        if '\nA:\n' in nl:
            prompt_with_problem = True
        else:
            prompt_with_problem = False

        if prompt_with_problem:
            [problem, code_snippet] = nl.split('\nA:\n')
            problem = '### ' + problem + '\n\n'
            code_snippet = '### Uncompleted Code Snippet:\n' + code_snippet
        else:
            code_snippet = '### Uncompleted Code Snippet:\n' + nl

        if prompt_with_problem:
            prompt = problem + '\n' + '### Potential Document:\n'
        else:
            prompt = '### Potential Document:\n'
        for doc in ret_docs:
            doc = truncate_too_long_doc(doc, max_length=1000)
            prompt += doc
            prompt += '\n'
        prompt += f'\n\n{code_snippet}'
        prompt += f'\n\n### Answer:\n{answer}'
        prompt += '\n\n\n### END\n\n\n'

        return prompt


    ds1000_loader = DS1000Loader()
    oracle_list = ds1000_loader.load_oracle_list()
    qs_list = ds1000_loader.load_qs_list()
    doc_list = ds1000_loader.load_doc_list()
    shots = 3
    prompt_type1, prompt_type2 = '', ''
    for idx in range(shots):
        type1_qs_id = sampled_rest_id_type1[idx]
        type2_qs_id = sampled_rest_id_type2[idx]

        type1_nl = [qs['nl'] for qs in qs_list if qs['qs_id'] == type1_qs_id]
        type2_nl = [qs['nl'] for qs in qs_list if qs['qs_id'] == type2_qs_id]
        assert len(type2_nl) == 1, len(type1_nl) == 1
        type1_nl, type2_nl = type1_nl[0], type2_nl[0]

        type1_answer = [oracle['output'] for oracle in oracle_list if oracle['qs_id'] == type1_qs_id]
        type2_answer = [oracle['output'] for oracle in oracle_list if oracle['qs_id'] == type2_qs_id]
        assert len(type2_answer) == 1, len(type1_answer) == 1
        type1_answer, type2_answer = type1_answer[0], type2_answer[0]

        type1_ret_libs = [oracle['doc_keys'] for oracle in oracle_list if oracle['qs_id'] == type1_qs_id]
        type2_ret_libs = [oracle['doc_keys'] for oracle in oracle_list if oracle['qs_id'] == type2_qs_id]
        assert len(type2_ret_libs) == 1, len(type1_ret_libs) == 1
        type1_ret_libs, type2_ret_libs = type1_ret_libs[0], type2_ret_libs[0]

        type1_ret_docs = []
        for line_idx, ret_lib in enumerate(type1_ret_libs):
            type1_ret_docs.append(f"potential document {line_idx}: {ret_lib}: {doc_list[ret_lib]}")
            type1_ret_docs[line_idx] = type1_ret_docs[line_idx].replace('\n', ' ')
        type2_ret_docs = []
        for line_idx, ret_lib in enumerate(type2_ret_libs):
            type2_ret_docs.append(f"potential document {line_idx}: {ret_lib}: {doc_list[ret_lib]}")
            type2_ret_docs[line_idx] = type2_ret_docs[line_idx].replace('\n', ' ')

        prompt_type1 += prepare_prompt(type1_nl, type1_ret_docs, type1_answer)
        prompt_type2 += prepare_prompt(type2_nl, type2_ret_docs, type2_answer)

    print([prompt_type1])
    print([prompt_type2])